{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.pyplot._IonContext at 0x2a69fe2c820>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tqdm.auto import tqdm\n",
        "from time import sleep\n",
        "import torchvision\n",
        "\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_covid = torch.load(r'C:\\Users\\hvard\\Desktop\\Neeraj_work\\Neeraj_work\\covid.pt', map_location=torch.device('cpu'))\n",
        "features_noncovid = torch.load(r'C:\\Users\\hvard\\Desktop\\Neeraj_work\\Neeraj_work\\health.pt',map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = torch.zeros((features_covid.shape[0]))\n",
        "test_labels = torch.ones((features_noncovid.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_feats = []\n",
        "train_label = []\n",
        "for i in range(250,len(test_labels)):\n",
        "    train_feats.append(features_covid[i])\n",
        "    train_feats.append(features_noncovid[i])\n",
        "    train_label.append(train_labels[i])\n",
        "    train_label.append(test_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_feats = []\n",
        "test_label = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0,250):\n",
        "    test_feats.append(features_covid[i])\n",
        "    test_feats.append(features_noncovid[i])\n",
        "    test_label.append(train_labels[i])\n",
        "    test_label.append(test_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_feats = torch.stack(train_feats)\n",
        "train_label = torch.stack(train_label)\n",
        "test_feats = torch.stack(test_feats)\n",
        "test_label = torch.stack(test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Loading Features and lables\n",
        "features_train = train_feats\n",
        "features_tlabel = train_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1958, 128])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_test = test_feats\n",
        "features_testlabel = test_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([500])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_testlabel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_np = features_train.squeeze().detach().numpy()\n",
        "t_np1 = features_test.squeeze().detach().numpy()\n",
        "t_np2 = features_tlabel.detach().numpy()\n",
        "t_np3 = features_testlabel.detach().numpy() #convert to Numpy array\n",
        "df = pd.DataFrame(t_np) \n",
        "df1 = pd.DataFrame(t_np1) \n",
        "df2 = pd.DataFrame(t_np2) \n",
        "df3 = pd.DataFrame(t_np3) #convert to a dataframe\n",
        "df.to_csv(\"trainfeatures\",index=False) #save to file\n",
        "df1.to_csv(\"testfeatures\",index=False)\n",
        "df2.to_csv(\"trainlabels\",index=False)\n",
        "df3.to_csv(\"testlabels\",index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainf = pd.read_csv(\"trainfeatures\")\n",
        "trainl = pd.read_csv(\"trainlabels\")\n",
        "testf = pd.read_csv(\"testfeatures\")\n",
        "testl = pd.read_csv(\"testlabels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "KNearest Neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.946\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.94      0.95       250\n",
            "         1.0       0.94      0.95      0.95       250\n",
            "\n",
            "    accuracy                           0.95       500\n",
            "   macro avg       0.95      0.95      0.95       500\n",
            "weighted avg       0.95      0.95      0.95       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[235  15]\n",
            " [ 12 238]]\n",
            "Sensitivity: 0.94\n",
            "Specificity: 0.952\n",
            "Precision 0.9407114624505929\n",
            "Recall:  0.952\n",
            "F1-Score : 0.9463220675944335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hvard\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainf, trainl, test_size=0.3)\n",
        "k_list = [3, 5, 7, 11, 21, 63, 255]\n",
        "'''for k in k_list:\n",
        "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
        "    neigh.fit(X_train, y_train)\n",
        "    accuracy = neigh.score(testf, testl)\n",
        "    print(\"Accuracy = \",acc,\" K= \",k)\n",
        "    '''\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "neigh.fit(X_train, y_train)\n",
        "y_pred = neigh.predict(testf)\n",
        "cm = confusion_matrix(testl, y_pred)\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, y_pred))\n",
        "print(\"Classification Report:\\n\",classification_report(testl,y_pred))\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(testl,y_pred))\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision\",precision_score(testl, y_pred))\n",
        "print(\"Recall: \", recall_score(testl, y_pred))\n",
        "print(\"F1-Score :\", f1_score(testl, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hvard\\AppData\\Local\\Temp/ipykernel_17248/1346995333.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  clf.fit(X_train,y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.948\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.95      0.95       250\n",
            "         1.0       0.95      0.94      0.95       250\n",
            "\n",
            "    accuracy                           0.95       500\n",
            "   macro avg       0.95      0.95      0.95       500\n",
            "weighted avg       0.95      0.95      0.95       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[238  12]\n",
            " [ 14 236]]\n",
            "Sensitivity: 0.952\n",
            "Specificity: 0.944\n",
            "Precision 0.9516129032258065\n",
            "Recall:  0.944\n",
            "F1-Score : 0.9477911646586344\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainf, trainl, test_size=0.3)\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(testf)\n",
        "cm = confusion_matrix(testl, y_pred)\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, y_pred))\n",
        "print(\"Classification Report:\\n\",classification_report(testl,y_pred))\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(testl,y_pred))\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision\",precision_score(testl, y_pred))\n",
        "print(\"Recall: \", recall_score(testl, y_pred))\n",
        "print(\"F1-Score :\", f1_score(testl, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decision Trees\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.926\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.94      0.93       250\n",
            "         1.0       0.93      0.92      0.93       250\n",
            "\n",
            "    accuracy                           0.93       500\n",
            "   macro avg       0.93      0.93      0.93       500\n",
            "weighted avg       0.93      0.93      0.93       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[234  16]\n",
            " [ 21 229]]\n",
            "Sensitivity: 0.936\n",
            "Specificity: 0.916\n",
            "Precision 0.9346938775510204\n",
            "Recall 0.916\n",
            "F1-Score 0.9252525252525253\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainf, trainl, test_size=0.3)\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(testf)\n",
        "cm = confusion_matrix(testl, y_pred)\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, y_pred))\n",
        "print(\"Classification Report:\",classification_report(testl,y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(testl, y_pred))\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision\",precision_score(testl, y_pred))\n",
        "print(\"Recall\", recall_score(testl, y_pred))\n",
        "print(\"F1-Score\", f1_score(testl, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.94\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.92      0.94       250\n",
            "         1.0       0.92      0.96      0.94       250\n",
            "\n",
            "    accuracy                           0.94       500\n",
            "   macro avg       0.94      0.94      0.94       500\n",
            "weighted avg       0.94      0.94      0.94       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[230  20]\n",
            " [ 10 240]]\n",
            "Sensitivity: 0.92\n",
            "Specificity: 0.96\n",
            "Precision 0.9230769230769231\n",
            "Recall 0.96\n",
            "F1-Score 0.9411764705882353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hvard\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainf, trainl, test_size=0.3)\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(testf)\n",
        "cm = confusion_matrix(testl, y_pred)\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, y_pred))\n",
        "print(\"Classification Report:\",classification_report(testl,y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(testl, y_pred))\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision\",precision_score(testl, y_pred))\n",
        "print(\"Recall\", recall_score(testl, y_pred))\n",
        "print(\"F1-Score\", f1_score(testl, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hvard\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.946\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.95       250\n",
            "         1.0       0.96      0.93      0.95       250\n",
            "\n",
            "    accuracy                           0.95       500\n",
            "   macro avg       0.95      0.95      0.95       500\n",
            "weighted avg       0.95      0.95      0.95       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[240  10]\n",
            " [ 17 233]]\n",
            "Sensitivity: 0.96\n",
            "Specificity: 0.932\n",
            "Precision 0.9588477366255144\n",
            "Recall 0.932\n",
            "F1-Score 0.9452332657200813\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(testf)\n",
        "cm = confusion_matrix(testl, y_pred)\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, y_pred))\n",
        "print(\"Classification Report:\",classification_report(testl,y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(testl, y_pred))\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision\",precision_score(testl, y_pred))\n",
        "print(\"Recall\", recall_score(testl, y_pred))\n",
        "print(\"F1-Score\", f1_score(testl, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.944\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94       250\n",
            "         1.0       0.95      0.93      0.94       250\n",
            "\n",
            "    accuracy                           0.94       500\n",
            "   macro avg       0.94      0.94      0.94       500\n",
            "weighted avg       0.94      0.94      0.94       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[239  11]\n",
            " [ 17 233]]\n",
            "Sensitivity: 0.956\n",
            "Specificity: 0.932\n",
            "Precision 0.9549180327868853\n",
            "Recall 0.932\n",
            "F1-Score 0.9433198380566802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hvard\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(testf)\n",
        "cm = confusion_matrix(testl, y_pred)\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, y_pred))\n",
        "print(\"Classification Report:\",classification_report(testl,y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(testl, y_pred))\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Precision\",precision_score(testl, y_pred))\n",
        "print(\"Recall\", recall_score(testl, y_pred))\n",
        "print(\"F1-Score\", f1_score(testl, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.962\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.96      0.96       250\n",
            "         1.0       0.96      0.97      0.96       250\n",
            "\n",
            "    accuracy                           0.96       500\n",
            "   macro avg       0.96      0.96      0.96       500\n",
            "weighted avg       0.96      0.96      0.96       500\n",
            "\n",
            "Confusion Matrix:\n",
            " [[239  11]\n",
            " [  8 242]]\n",
            "Precision 0.9565217391304348\n",
            "Sensitivity :  0.956\n",
            "Specificity :  0.968\n",
            "Recall:  0.968\n",
            "f1-score: 0.9622266401590457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hvard\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return f(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainf, trainl, test_size=0.3)\n",
        "model = LogisticRegression(solver='liblinear', random_state=0)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict_proba(testf)\n",
        "cm = confusion_matrix(testl, model.predict(testf))\n",
        "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print(\"Accuracy:\",accuracy_score(testl, model.predict(testf)))\n",
        "print(\"Classification Report:\\n\",classification_report(testl,model.predict(testf)))\n",
        "print(\"Confusion Matrix:\\n\",cm)\n",
        "print(\"Precision\",precision_score(testl, model.predict(testf)))\n",
        "print('Sensitivity : ', sensitivity )\n",
        "print('Specificity : ', specificity)\n",
        "print(\"Recall: \", recall_score(testl, model.predict(testf)))\n",
        "print(\"f1-score:\",f1_score(testl, model.predict(testf)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
